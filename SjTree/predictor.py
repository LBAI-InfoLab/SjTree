

def filter_spotted_C4(X_data, y_data, preds):
    """
    Get rids of predicted C4 patients in the dataframe

        - X_data is the main dataframe
        - y_data is an array, the associated label of the main dataset
        - preds is the prediction performed by the C4 classifier

    => return the updated dataframe and associated label for further processing
       by the C1C2C3 model
    """

    ## add Spot C4 column
    X_data['Spot_C4'] = preds

    ## drop spoted C4
    X_data = X_data[X_data['Spot_C4'].isin([0])]

    ## drop spoted C4 column
    X_data = X_data.drop(columns=['Spot_C4'])

    ## deal with y
    updated_label = []
    cmpt = 0
    for y in y_data:
        if(preds[cmpt] == 0):
            updated_label.append(y)
        cmpt +=1

    ## return dataframe
    return X_data, updated_label


def preprocess_data(dataframe, feature_file):
    """
    Reformat dataset using only features present in feature_file

        - dataframe is a dataframe containing the patient's data
        - feature_file is a string, the name of the file containing
          the list of the features to keep

    => return a processed dataframe
    """

    ## importation
    import pandas as pd

    ## load features
    df_features = pd.read_csv(feature_file)
    feature_list = list(df_features['FEATURE'])

    ## check that features are present in dataset
    for f in feature_list:
        if(f not in list(dataframe.keys())):
            print("[!] ERROR => feature "+str(f)+" not found in dataset")
            return None

    ## select features in dataset
    dataframe = dataframe[feature_list]

    ## return preprocess data
    return dataframe


def assemble_prediction(C4_prediction, mult_prediction):
    """
    Assemble prediction from C4 and multi models

        - C4_prediction is an array of prediction generated by the C4 model
        - mult_prediction is an array of prediction generated by the C1C2C3 model

    => return an array of all preidction generated by the composite model
    """

    ## parameters
    global_prediction = []
    cmpt = 0

    ## fusion list
    for pred in C4_prediction:
        if(pred == 1):
            global_prediction.append(4)
        else:
            cluster = mult_prediction[cmpt]+1
            global_prediction.append(cluster)
            cmpt +=1

    ## return global_prediction
    return global_prediction



def plot_model_tree():
    """
    Generate a png image for each decision tree used by the C4 and C1C2C3 model.
    Tree composition are extracted from the models files in the models folder
    (models/C4_model.model and models/C1C2C3.model).
    Images are created in the images folder.
    """

    ## importation
    import joblib
    import matplotlib.pyplot as plt
    import xgboost as xgb

    ## parameters
    C4_model_file = "models/C4_model.model"
    multiclass_model_file = "models/C1C2C3.model"

    ## load models
    C4_detector = joblib.load(C4_model_file)
    multi_classifier = joblib.load(multiclass_model_file)

    ## generate figure for C4
    dump_list = C4_detector.get_booster().get_dump()
    num_trees = len(dump_list)
    for x in range(0,num_trees):
        xgb.plot_tree(C4_detector,num_trees=x)
        plt.tight_layout()
        plt.savefig("images/C4_detector_tree_"+str(x)+".png", dpi=600)
        plt.close()

    ## generate figure for multi
    dump_list = multi_classifier.get_booster().get_dump()
    num_trees = len(dump_list)
    for x in range(0,num_trees):
        xgb.plot_tree(multi_classifier,num_trees=x)
        plt.tight_layout()
        plt.savefig("images/C1C2C3_classifier_tree_"+str(x)+".png", dpi=600)
        plt.close()




def plot_cluster_distribution(prediction):
    """
    Generate png image for the cluster distribution predicted by the model.

        - prediction is an array, list of all prediction generated by the
          composite model (obtain with the function assemble_prediction)
    """

    ## importation
    import matplotlib.pyplot as plt
    import numpy as np

    ## parameters
    ref_to_count_disc = {"C1":79, "C2":60, "C3":66, "C4":22}
    ref_to_count_all = {"C1":101, "C2":77, "C3":88, "C4":38}

    ## craft figure
    cluster_to_count = {"C1":0, "C2":0, "C3":0, "C4":0}
    for p in prediction:
        if(p == 1):
            cluster_to_count["C1"] += 1
        elif(p==2):
            cluster_to_count["C2"] += 1
        elif(p==3):
            cluster_to_count["C3"] += 1
        elif(p==4):
            cluster_to_count["C4"] += 1

    ## craft simple distribution
    plt.bar(cluster_to_count.keys(), cluster_to_count.values())
    plt.savefig("images/cluster_proportion.png")
    plt.close()



def run(data_file, verbose_mode):
    """
    Run the model

        - data_file is a string, the name of the file containing the data
        - verbose_mode is a boolean, usually set to True

    => Generate the dataset/prediction.csv file, where each ID is assigned to
       its predicted cluster.
    """

    ## importation
    import pandas as pd
    import joblib
    from sklearn.metrics import accuracy_score
    from sklearn.metrics import confusion_matrix
    import matplotlib.pyplot as plt

    ## silence pandas warning
    pd.options.mode.chained_assignment = None

    ## parameters
    C4_model_file = "models/C4_model.model"
    multiclass_model_file = "models/C1C2C3.model"

    ## Load dataset
    df_data = pd.read_csv(data_file)
    patient_id = df_data['ID']
    X = df_data.drop(columns=['ID'])
    y = df_data['ID']
    y['preds'] = "NA"
    y = list(y['preds'])
    patient_id = list(df_data['ID'])

    ## display information if needed
    if(verbose_mode):
        print("[+] Run prediction")


    ##------------##
    ## PREDICTION ##############################################################
    ##------------##

    ## 1. Call First Model
    # -> prepocess data for model
    C4_X = preprocess_data(X, "ressources/C4_features.csv")

    # -> Load model
    C4_detector = joblib.load(C4_model_file)

    # -> Guess if observation is C4 or not
    C4_preds = C4_detector.predict(C4_X)

    # -> compute assignation proba
    C4_preds_proba = C4_detector.predict_proba(C4_X)

    ## save prediction results

    ## update dataset
    # -> drop patient predicted as C4
    X, y = filter_spotted_C4(X, y, C4_preds)

    ## 2. Call Main Model
    #-> preprocess data for model
    X = preprocess_data(X, "ressources/multi_features.csv")

    #-> load model
    multi_classifier = joblib.load(multiclass_model_file)

    # -> Multiclassification between C1,C2,C3
    multi_preds = multi_classifier.predict(X)

    # -> compute assignation proba
    multi_preds_proba = multi_classifier.predict_proba(X)

    ## assemble predictions of the model
    global_prediction = assemble_prediction(C4_preds, multi_preds)

    ## assemble probablilities for each cluster assignation
    global_proba = assemble_proba(C4_preds_proba, multi_preds_proba)

    ## check distribution
    plot_cluster_distribution(global_prediction)

    ## create manifest file
    manifest_file = open('dataset/prediction.csv', 'w')
    manifest_file.write("ID,PREDICTION\n")
    cmpt = 0
    for pred in global_prediction:
        line_to_write = str(patient_id[cmpt])+","+str(pred)
        manifest_file.write(line_to_write+"\n")
        cmpt +=1
    manifest_file.close()

    ## create proba file
    proba_file = open('dataset/probabilities.csv', 'w')
    proba_file.write("ID,Non-C4,C4,C1,C2,C3,PREDICTION\n")
    cmpt = 0
    for prob in global_proba:
        pred = global_prediction[cmpt]
        line_to_write = str(patient_id[cmpt])+","+str(prob[0])+","+str(prob[1])+","+str(prob[2])+","+str(prob[3])+","+str(prob[4])+","+str(pred)
        proba_file.write(line_to_write+"\n")
        cmpt +=1
    proba_file.close()

    ## display information if needed
    if(verbose_mode):
        print("[+] Prediction complete")
